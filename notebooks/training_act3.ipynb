{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhered/robotica_patito_pycon2025/blob/main/notebooks/training_act3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edited by MH. This Notebook used to add episodes after training the base model."
      ],
      "metadata": {
        "id": "ELVqt9SpCv6i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQUk3Y0WwYZ4"
      },
      "source": [
        "# ü§ó x ü¶æ: Training ACT with LeRobot Notebook\n",
        "\n",
        "Welcome to the **LeRobot ACT training notebook**! This notebook provides a ready-to-run setup for training imitation learning policies using the [ü§ó LeRobot](https://github.com/huggingface/lerobot) library.\n",
        "\n",
        "In this example, we train an `ACT` policy using a dataset hosted on the [Hugging Face Hub](https://huggingface.co/), and optionally track training metrics with [Weights & Biases (wandb)](https://wandb.ai/).\n",
        "\n",
        "## ‚öôÔ∏è Requirements\n",
        "- A Hugging Face dataset repo ID containing your training data (`--dataset.repo_id=YOUR_USERNAME/YOUR_DATASET`)\n",
        "- Optional: A [wandb](https://wandb.ai/) account if you want to enable training visualization\n",
        "- Recommended: GPU runtime (e.g., NVIDIA A100) for faster training\n",
        "\n",
        "## ‚è±Ô∏è Expected Training Time\n",
        "Training with the `ACT` policy for 100,000 steps typically takes **about 1.5 hours on an NVIDIA A100** GPU. On less powerful GPUs or CPUs, training may take significantly longer.\n",
        "\n",
        "## Example Output\n",
        "Model checkpoints, logs, and training plots will be saved to the specified `--output_dir`. If `wandb` is enabled, progress will also be visualized in your wandb project dashboard.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ö†Ô∏è Before running any cells, select A100 GPU runtime type (requires making a purchase, the cheapest option of 100 units pay as you go  for ~10‚Ç¨ will be plenty. 1-2hrs of training expected)."
      ],
      "metadata": {
        "id": "iX4rN5vSIm-_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOJyX0CnwA5m"
      },
      "source": [
        "## Install conda\n",
        "This cell uses `condacolab` to bootstrap a full Conda environment inside Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlKjL1X5t_zM"
      },
      "outputs": [],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxCc3CARwUjN"
      },
      "source": [
        "## Install LeRobot\n",
        "This cell clones the `lerobot` repository from Hugging Face, installs FFmpeg (version 7.1.1), and installs the package in editable mode.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgLu7QT5tUik"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/huggingface/lerobot.git\n",
        "!conda install ffmpeg=7.1.1 -c conda-forge\n",
        "!cd lerobot && pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More setup\n",
        "This cell installs `tree` and the git credential helper"
      ],
      "metadata": {
        "id": "HnOvESvIXka0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -qq update && apt-get -qq install -y tree\n",
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "Dw193ZwBXk8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Sn2wG4wldo"
      },
      "source": [
        "## Login onto Weights & Biases and Huggingface Hub\n",
        "The first cell logs you into Weights & Biases (wandb) to enable experiment tracking and logging. Go to https://wandb.ai/authorize to obtain the API key (you need to sign up first if you haven't already) and paste it on the first cell when requested.\n",
        "\n",
        "The second cell logs you into the Huggingface Hub to upload checkpoints.\n",
        "Go to https://huggingface.co/settings/tokens to create a token (you need to sign up first) then create a token. I called it `collab-pycon`. Paste it in the second cell below. Note: for successive runs you need to click on invalidate & refresh the token and paste it again.\n",
        "\n",
        "Say Yes to adding the token as git credential."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PolVM_movEvp"
      },
      "outputs": [],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yu5khQGIHi6"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkzTo4mNwxaC"
      },
      "source": [
        "## Training ACT with LeRobot\n",
        "\n",
        "This cell runs the `train.py` script from the `lerobot` library to train a robot control policy.  \n",
        "\n",
        "Make sure to adjust the following arguments to your setup:\n",
        "\n",
        "1. `--dataset.repo_id=USER/REPO_NAME`:  \n",
        "   Replace this with the Hugging Face Hub repo ID where your dataset is stored, e.g., `mhered/recording_test`.\n",
        "\n",
        "2. `--policy.type=act`:  \n",
        "   Specifies the policy configuration to use. `act` refers to [configuration_act.py](../lerobot/common/policies/act/configuration_act.py), which will automatically adapt to your dataset‚Äôs setup (e.g., number of motors and cameras).\n",
        "\n",
        "3. `--output_dir=outputs/train/...`:  \n",
        "   Directory where training logs and model checkpoints will be saved.\n",
        "\n",
        "4. `--job_name=...`:  \n",
        "   A name for this training job, used for logging and Weights & Biases.\n",
        "\n",
        "5. `--policy.device=cuda`:  \n",
        "   Use `cuda` if training on an NVIDIA GPU. Use `mps` for Apple Silicon, or `cpu` if no GPU is available.\n",
        "\n",
        "6. `--wandb.enable=true`:  \n",
        "   Enables Weights & Biases for visualizing training progress. You must be logged in via `wandb login` before running this.\n",
        "\n",
        "Note: If runtime disconnects before a checkpoint is reached and uploaded you cannot resume, lose progress is lost. By default the first checkpoint is fater 20k steps!!\n",
        "Note: three versions of the train command are provided:\n",
        "* one to launch training the first time.\n",
        "* one to resume training when there is still a local `training_state`\n",
        "* one to warm start from the weights in the last checkpoint saved in the Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ufss6US6xbpi"
      },
      "outputs": [],
      "source": [
        "# use this to warm start from saved Hub weights after adding more episodes. Here # steps is the number of steps to do\n",
        "!cd lerobot && lerobot-train \\\n",
        "--dataset.repo_id=mhered/recording-test \\\n",
        "--policy.type=act \\\n",
        "--output_dir=outputs/train/act_so100_pato_test \\\n",
        "--job_name=act_so100_pato_test2 \\\n",
        "--policy.device=cuda \\\n",
        "--wandb.enable=true \\\n",
        "--policy.repo_id=mhered/my_act2 \\\n",
        "--policy.pretrained_path=mhered/my_act \\\n",
        "--steps=20000 \\\n",
        "--save_checkpoint=true \\\n",
        "--save_freq=2000 \\\n",
        "--eval_freq=2000 \\\n",
        "--policy.use_amp=true \\\n",
        "--num_workers=2 \\\n",
        "--policy.push_to_hub=false\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVE-j_dBCdGF"
      },
      "source": [
        "## Upload checkpoint to Hugging Face Hub\n",
        "Now after training is done check the checkpoints created and upload the last checkpoint to the Hugging Face hub at https://huggingface.co/mhered/my_act2/tree/main"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tree /content/lerobot/outputs/train/act_so100_pato_test/checkpoints"
      ],
      "metadata": {
        "id": "R5SryWSmhc-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFMLGuVkH7UN"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli upload mhered/my_act2 \\\n",
        "/content/lerobot/outputs/train/act_so100_pato_test/checkpoints/last/pretrained_model \\\n",
        "--repo-type model --commit-message \"Upload last checkpoint\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Disconnect to avoid consuming compute"
      ],
      "metadata": {
        "id": "-GtFerOmYCm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "gzuICadoeB0P"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}